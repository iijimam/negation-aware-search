# /home/irisowner/.local/bin/streamlit run /src/UI_sqlalchemy/app.py --server.port 8090 --logger.level=debug
#
import streamlit as st
from openai import OpenAI
from typing import Any, Dict, List, Tuple,Optional
import json
import time,datetime
import sys
sys.path+=["/src/UI_sqlalchemy"]
import search

client = OpenAI()  # ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’åˆ©ç”¨
MODEL = "gpt-4o-mini"  #ã™ã§ã«æ±ºã¾ã£ãŸ Top3 ã‚’ã€ãƒ«ãƒ¼ãƒ«ã«æ²¿ã£ã¦æ©Ÿæ¢°çš„ã«åˆ¤å®šã™ã‚‹ãŸã‚ã€4.1-miniã§ã¯ãªã„ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨

SYSTEM_PROMPT = """
ã‚ãªãŸã¯ãƒ©ãƒ³ã‚­ãƒ³ã‚°å€™è£œ(top3)ã®å¦¥å½“æ€§ã‚’åˆ¤å®šã™ã‚‹ Judge ã§ã™ã€‚
åˆ¤å®šã«ä½¿ã†æƒ…å ±ã¯ã€Œquery_flags ã¨ ranked_top3[].FlagsJson ã® valueã€ã®ã¿ã€‚
query_text / SectionText / evidence ã®æ–‡ç« ã‚’èª­ã‚“ã§å†è§£é‡ˆã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚

# å€¤ã®æ‰±ã„
value ã¯ 1/0/nullã€‚null ã¯ã€Œä¸æ˜ã€ã§ã‚ã‚ŠçŸ›ç›¾ã§ã¯ãªã„ã€‚

# mismatch ã¯å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾ã ã‘ï¼ˆã“ã‚Œä»¥å¤–ã§ mismatch ç¦æ­¢ï¼‰
å¼·ãƒ•ãƒ©ã‚° = HasICUCare, HasNPPV, HasMechanicalVentilation, HasIntubation, HasDialysis, HasVasopressor
mismatch æ¡ä»¶ã¯æ¬¡ã®2ã¤ã®ã¿:
(A) query=1 ã‹ã¤ doc=0
(B) query=1 ã‹ã¤ doc!=1ï¼ˆdocãŒnull/0ã‚’å«ã‚€ï¼‰
â€»å¼·ãƒ•ãƒ©ã‚°ä»¥å¤–ã¯(A)(B)ã‚’é©ç”¨ã—ãªã„ã€‚

# å¼±ãƒ•ãƒ©ã‚°ã¯ decision ã«ä½¿ã‚ãªã„ï¼ˆçµ¶å¯¾ï¼‰
å¼±ãƒ•ãƒ©ã‚° = HasOxygenTherapy, HasAntibioticsIV, HasAntibioticsPO, HasSteroidSystemic
å¼±ãƒ•ãƒ©ã‚°ã¯ã€Œèª¬æ˜ã«æ›¸ã„ã¦ã‚ˆã„ã€ã ã‘ã§ã€is_similar_enough ã®åˆ¤å®šæ ¹æ‹ ã«ã—ã¦ã¯ã„ã‘ãªã„ã€‚

# verdict ãƒ«ãƒ¼ãƒ«
- match: å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾ãŒãªãã€ä¸»è¦ãƒ•ãƒ©ã‚°ã®æ•´åˆãŒé«˜ã„
- partial: å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾ã¯ãªã„ãŒã€æƒ…å ±ãŒè–„ãç¢ºä¿¡ãŒå¼±ã„
- mismatch: å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾(A)(B)ãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°å¿…ãš mismatch

# decision ã®ä½œã‚Šæ–¹ï¼ˆå¼·åˆ¶ãƒ»ä¾‹å¤–ãªã—ï¼‰
- decision.top_doc_id = ranking[0].doc_id
- decision.is_similar_enough = (ranking[0].verdict != "mismatch")
- decision.summary ã¯ ranking[0] ã® verdict ã¨ã€å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾ã®æœ‰ç„¡ã ã‘ã‚’çŸ­ãè¿°ã¹ã‚‹ã€‚
  ã€Œç¢ºèªã•ã‚Œã¦ã„ã‚‹ã€ã€Œã€œãŒè¡Œã‚ã‚ŒãŸã€ç­‰ã®è‡¨åºŠã‚¤ãƒ™ãƒ³ãƒˆæ–­å®šã¯ç¦æ­¢ï¼ˆvalue=1 ã®ãƒ•ãƒ©ã‚°åã ã‘æ›¸ãï¼‰ã€‚

# reasons ã® status åˆ¤å®šï¼ˆæ©Ÿæ¢°çš„ãƒ«ãƒ¼ãƒ«ï¼‰
å„ãƒ•ãƒ©ã‚°ã”ã¨ã«ä»¥ä¸‹ã§ status ã‚’æ±ºã‚ã‚‹ï¼ˆä¾‹å¤–ãªã—ï¼‰:

(1) query ãŒ null ã¾ãŸã¯ doc ãŒ null â†’ status=neutral
(2) query ãŒ 0/1 ã§ doc ãŒ 0/1 ã‹ã¤ä¸€è‡´ â†’ status=match
(3) query ãŒ 0/1 ã§ doc ãŒ 0/1 ã‹ã¤ä¸ä¸€è‡´ â†’ status=contradict
ãŸã ã— (3) ã® "contradict" ã‚’è¨±å¯ã™ã‚‹ã®ã¯ã€Œå¼·ãƒ•ãƒ©ã‚°ã€ã‹ã¤ query=1 & doc!=1 ã®ã¨ãã®ã¿ã€‚
ãã‚Œä»¥å¤–ã®ä¸ä¸€è‡´ã¯ã™ã¹ã¦ neutral ã¨ã™ã‚‹ï¼ˆå¼±ãƒ•ãƒ©ã‚°ã¯æ±ºã—ã¦ contradict ã«ã—ãªã„ï¼‰ã€‚

# å‡ºåŠ›
å¿…ãšJSONã®ã¿:
{
  "decision": {"top_doc_id": <int>, "is_similar_enough": <bool>, "confidence": <0-1>, "summary": "<çŸ­ã„æ—¥æœ¬èª>", "missing_info": []},
  "ranking": [{"doc_id": <int>, "rank": 1, "relevance": <0-1>, "verdict": "match|partial|mismatch", "reasons": [...]}, ...]
}
"""

JUDGE_SCHEMA: Dict[str, Any] = {
    "type": "object",
    "additionalProperties": False,
    "required": ["decision", "ranking"],
    "properties": {
        "decision": {
            "type": "object",
            "additionalProperties": False,
            "required": ["top_doc_id","is_similar_enough", "confidence", "summary", "missing_info"],
            "properties": {
                "top_doc_id": {"type": "number"},
                "is_similar_enough": {"type": "boolean"},
                "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0},
                "summary": {"type": "string"},
                "missing_info": {"type": "array", "items": {"type": "string"}},
            },
        },
        "ranking": {
            "type": "array",
            "minItems": 3,
            "maxItems": 3,
            "items": {
                "type": "object",
                "additionalProperties": False,
                "required": ["doc_id", "rank", "relevance", "verdict", "reasons"],
                "properties": {
                    "doc_id": {"type": "number"},
                    "rank": {"type": "number"},
                    "relevance": {"type": "number", "minimum": 0.0, "maximum": 1.0},
                    "verdict": {"type": "string", "enum": ["match", "partial", "mismatch"]},
                    "reasons": {"type": "array", "items": {"type": "string"}, "maxItems": 5},
                },
            },
        },
    },
}

def build_user_prompt(item: dict) -> str:
    return f"""æ¬¡ã®å…¥åŠ›(JSON)ã«ã¤ã„ã¦åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

å…¥åŠ›(JSON):
<<<
{json.dumps(item, ensure_ascii=False)}
>>>

æœ€é‡è¦: decision ã¯ã€Œrank1ï¼ˆæœ€ä¸Šä½å€™è£œï¼‰ã«å¯¾ã™ã‚‹çµè«–ã€ã¨ã™ã‚‹ã€‚
- decision.is_similar_enough ã¯ rank1 ã®å€™è£œãŒã‚¯ã‚¨ãƒªã¨é¡ä¼¼ã—ã¦ã„ã‚‹ã‹ã®ã¿ã§åˆ¤å®šã™ã‚‹ã€‚
- rank2/3 ã«çŸ›ç›¾ãŒã‚ã£ã¦ã‚‚ decision ã‚’ False ã«ã—ã¦ã¯ã„ã‘ãªã„ï¼ˆdecision ã¯ rank1 ã®ã¿ã‚’è¦‹ã‚‹ï¼‰ã€‚
- decision.summary / decision.reasons ã¯ rank1 ã®å†…å®¹ã ã‘ã«åŸºã¥ã„ã¦æ›¸ãã€‚rank2/3 ã«è¨€åŠã—ãªã„ã€‚
- decision.top_doc_id ã¨ decision.top_rank ã‚’å¿…ãšå‡ºåŠ›ã™ã‚‹ï¼ˆtop_rankã¯å¸¸ã«1ï¼‰ã€‚

decision ã¨ verdict ã®æ•´åˆ:
- rank1.verdict ãŒ match ã®ã¨ãã€decision.is_similar_enough ã¯å¿…ãš true
- rank1.verdict ãŒ mismatch ã®ã¨ãã€decision.is_similar_enough ã¯å¿…ãš false
- rank1.verdict ãŒ partial ã®ã¨ãã¯ true/false ã©ã¡ã‚‰ã‚‚å¯ï¼ˆconfidenceã§èª¿æ•´ï¼‰

åˆ¤å®šã®å„ªå…ˆé †ä½:
(1) ã‚¯ã‚¨ãƒªã§æ˜ç¤ºã•ã‚ŒãŸãƒ•ãƒ©ã‚°(0/1)ã®ä¸€è‡´ãƒ»çŸ›ç›¾ï¼ˆæœ€é‡è¦ï¼‰
(2) ICU/NPPV/MVãªã©é‡ç—‡åº¦ã‚¤ãƒ™ãƒ³ãƒˆã®çŸ›ç›¾
(3) ç–¾æ‚£ï¼ˆè‚ºç‚ãªã©ï¼‰ã®ä¸€è‡´
(4) è»¢å¸°ã‚„ç´°éƒ¨ã¯è£œåŠ©
nullã¯ã€Œä¸æ˜ã€ã§ã‚ã‚Šã€0ã¨ã¯é•ã†ã€‚

åˆ¶ç´„:
- rankingã¯å¿…ãš3ä»¶(å…¥åŠ›ã®3å€™è£œã‚’å¿…ãšå«ã‚ã‚‹)
- reasonsã¯å„å€™è£œ æœ€å¤§5å€‹ã€çŸ­ãå…·ä½“çš„ã«ã€ã‚¯ã‚¨ãƒªã§æ˜ç¤ºã•ã‚ŒãŸãƒ•ãƒ©ã‚°(0/1)ã¨ç–¾æ‚£ãƒ»é‡ç—‡åº¦ã‚’ä¸­å¿ƒã«
- relevanceã¯0.0ã€œ1.0
- relevanceã¯ç›¸å¯¾å€¤ã€‚rank1>rank2>rank3 ã¨ãªã‚‹ã‚ˆã†ã«å·®ã‚’ã¤ã‘ã‚‹ã“ã¨ï¼ˆåŒç‚¹ç¦æ­¢ï¼‰
- verdictã®å®šç¾©ã¯ä»¥ä¸‹ã®é€šã‚Š:
    - match: å¼·ãƒ•ãƒ©ã‚°(ICU/NPPV/MV/æŒ¿ç®¡/é€æ/æ˜‡åœ§å‰¤)ã®çŸ›ç›¾ãŒãªãã€ä¸»è¦æƒ…å ±ãŒæ•´åˆ
    - partial: å¼·ãƒ•ãƒ©ã‚°çŸ›ç›¾ã¯ãªã„ãŒã€æƒ…å ±ãŒè–„ã„/ç–¾æ‚£ãŒä¸æ˜/å¼±ãƒ•ãƒ©ã‚°ãŒæƒã‚ãšç¢ºä¿¡ãŒå¼±ã„
    - mismatch: å¼·ãƒ•ãƒ©ã‚°ã«é™ã‚Šã€ã‚¯ã‚¨ãƒªã§æ˜ç¤º(query=1)ã•ã‚ŒãŸå¼·ãƒ•ãƒ©ã‚°ãŒ doc ã§æº€ãŸã•ã‚Œãªã„å ´åˆã®ã¿
      (query=1 & doc!=1)
â€»HasOxygenTherapy ã‚’å«ã‚€å¼±ãƒ•ãƒ©ã‚°ã§ã¯ mismatch ã«ã—ãªã„
- ã‚¯ã‚¨ãƒªã§æœªè¨€åŠ(value=null)ã®å¼±ãƒ•ãƒ©ã‚°(Sepsis, Shock, AKI, Diabetes, InsulinUse, AntibioticsIV/PO, SteroidSystemic)ã¯ã€verdict ã‚’ä¸‹ã’ã‚‹ä¸»è¦å› ã«ã—ãªã„ã€‚
- ã‚¯ã‚¨ãƒªã§æœªè¨€åŠã®ãƒ•ãƒ©ã‚°ï¼ˆé…¸ç´ ãªã©ï¼‰ã§ mismatch ã«ã—ãªã„
- decision.top_doc_id ã¯ ranking[0].doc_id(rank=1ã®å€™è£œ)ã¨åŒã˜å€¤ã«ã™ã‚‹ã€‚
- JSONä»¥å¤–ã¯ç¦æ­¢
"""

def call_judge(
    client: OpenAI,
    model: str,
    item: dict,
    temperature: float = 0.0,
    max_output_tokens: int = 900,
    retries: int = 4,
) -> dict:
    last_err = None
    user_prompt = build_user_prompt(item)
    print(item)

    for attempt in range(1, retries + 1):
        try:
            resp = client.responses.create(
                model=model,
                input=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=temperature,
                max_output_tokens=max_output_tokens,
                #  JSON Schemaã§å‡ºåŠ›ã‚’åˆ¶ç´„
                text={
                    "format": {
                        "type": "json_schema",
                        "name": "judge_result",
                        "strict": True,
                        "schema": JUDGE_SCHEMA,
                    }
                },
            )

            # è¿”ã£ã¦ããŸãƒ†ã‚­ã‚¹ãƒˆ(JSON)ã‚’ãƒ‘ãƒ¼ã‚¹
            return json.loads(resp.output_text)

        except Exception as e:
            last_err = e
            time.sleep(min(6.0, 0.6 * (2 ** (attempt - 1))))

    raise RuntimeError(f"Judge failed: {last_err}") from last_err

def read_jsonl(path: str) -> List[Dict[str, Any]]:
    rows: List[Dict[str, Any]] = []
    with open(path, "r", encoding="utf-8") as f:
        for i, line in enumerate(f, start=1):
            line = line.strip()
            if not line:
                continue
            try:
                rows.append(json.loads(line))
            except json.JSONDecodeError as e:
                raise ValueError(f"JSON decode error at line {i}: {e}") from e
    return rows


def write_jsonl(path: str, rows: List[Dict[str, Any]]) -> None:
    with open(path, "w", encoding="utf-8") as f:
        for r in rows:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

def normalize_flagsjson_to_dict(flagsjson: Any) -> Dict[str, Any]:
    """
    å…¥åŠ› flagsjson ãŒ
      - flags.v2 å½¢å¼ã® dict
      - æ—§å½¢å¼ list[{"FlagName":..., "Value":...}]
      - JSONæ–‡å­—åˆ—ï¼ˆdict or listï¼‰
    ã®ã©ã‚Œã§ã‚‚å—ã‘ã¦ã€æœ€çµ‚çš„ã« {"HasX": {"value": ...}, ...} ã‚’è¿”ã™
    """
    if flagsjson is None:
        return {}

    # 1) JSONæ–‡å­—åˆ—ãªã‚‰ãƒ‘ãƒ¼ã‚¹ã‚’è©¦ã™
    if isinstance(flagsjson, str):
        s = flagsjson.strip()
        if not s:
            return {}
        try:
            flagsjson = json.loads(s)
        except json.JSONDecodeError:
            # JSONæ–‡å­—åˆ—ã§ãªã„ãªã‚‰è«¦ã‚ã¦ç©º
            return {}

    # 2) ã™ã§ã« dict ã®å ´åˆ
    if isinstance(flagsjson, dict):
        # flags.v2 ã®å…¥ã‚Œå­ï¼ˆ{"flags": {...}}ï¼‰ãªã‚‰ä¸­èº«ã‚’è¿”ã™
        if "flags" in flagsjson and isinstance(flagsjson["flags"], dict):
            return flagsjson["flags"]
        # ã™ã§ã« {"HasX": {"value": ...}} å½¢å¼ãªã‚‰ãã®ã¾ã¾
        return flagsjson

    # 3) list ã®å ´åˆï¼ˆæ—§å½¢å¼æƒ³å®šï¼‰
    if isinstance(flagsjson, list):
        d: Dict[str, Any] = {}
        for it in flagsjson:
            if not isinstance(it, dict):
                continue
            k = it.get("FlagName")
            if not k:
                continue
            d[k] = {"value": it.get("Value")}
        return d

    # 4) ãã®ä»–ã¯ç©º
    return {}

def excerpt(s: str, max_chars: int = 700) -> str:
    s = (s or "").strip()
    if len(s) <= max_chars:
        return s
    return s[:max_chars] + "â€¦(truncated)"

from datetime import date

def fmt_date(d):
    if d is None:
        return None
    if isinstance(d, date):
        return d.isoformat()  # 'YYYY-MM-DD'
    return str(d)

st.set_page_config(page_title="é€€é™¢æ™‚ã‚µãƒãƒªé¡ä¼¼æ¤œç´¢", layout="wide")
st.title("é€€é™¢æ™‚ã‚µãƒãƒªé¡ä¼¼æ¤œç´¢ï¼‹ãƒªãƒ©ãƒ³ã‚¯ï¼‹LLM as judge")


# å…¥åŠ›æ¬„
if query := st.chat_input("é¡ä¼¼æ¤œç´¢ç”¨ã®è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„>>"):
    st.markdown(f"### å…¥åŠ›è³ªå•:\n{query}")
    with st.spinner("LLMã§ãƒ•ãƒ©ã‚°æŠ½å‡ºï¼‹é¡ä¼¼æ¤œç´¢ã€ãƒªãƒ©ãƒ³ã‚¯å®Ÿè¡Œä¸­...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
        ranking_result,search_top3 = search.get_simirality_ranking(query)
        with st.expander("ğŸ” ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœï¼ˆãƒªãƒ©ãƒ³ã‚¯å¾Œï¼‰ï¼šãƒ‡ãƒãƒƒã‚°", expanded=False):
            search_map = {
                r["DocId"]: r
                for r in search_top3
            }
            ranked_top3_with_text = []
            for r in ranking_result["ranked_top3"]:
                docid = r["DocId"]
                src = search_map.get(docid, {})

                ranked_top3_with_text.append({
                    "PatientId": src.get("PatientId"),
                    "DischargeDate": fmt_date(src.get("DischargeDate")),
                    "SectionText": src.get("SectionText"),
                    **r,  # judge_top3 ã®ä¸­èº«ï¼ˆranking_resultã®ä¸­èº«ï¼‰
                })
            ranking_out={
                "query_text": ranking_result["query_text"],
                "query_flags": ranking_result["query_flags"],
                "stage1": ranking_result["stage1"],
                "ranking":ranked_top3_with_text
            }
            st.write(ranking_out)

    # LLM as a Judge
    with st.spinner("å¯©æŸ»ä¸­...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
        #ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®3ä»¶
        top3_raw = ranking_result.get("ranked_top3")
        if not isinstance(top3_raw, list) or len(top3_raw) != 3:
            raise ValueError(f"ranked_top3 must have exactly 3 items.")
        out_rows: List[Dict[str, Any]] = []
        # ===== ã“ã“ã§ judge ç”¨ã« FlagsJson ã‚’ dict åŒ–ã™ã‚‹ =====
        top3_for_judge = []
        for c in top3_raw:
            c2 = dict(c)
            if isinstance(c.get("FlagsJson"), str):
                print(f"FlagsJson is str (DocId={c.get('DocId')}), head={c.get('FlagsJson')[:80]}")
            c2["FlagsJson"] = normalize_flagsjson_to_dict(c.get("FlagsJson"))
            top3_for_judge.append(c2)

        item_for_judge = {
            "query_flags": ranking_result["query_flags"],
            "ranked_top3": [
                {
                    "DocId": c["DocId"],
                    "FlagsJson": c["FlagsJson"],
                }
                for c in top3_for_judge
            ]
        }
        # =====================================================

        temperature = 0.0  # å›ºå®š
        judge_result = call_judge(
            client=client,
            model=MODEL,
            item=item_for_judge,
            temperature=temperature,
            max_output_tokens=900,
        )

        out_rows.append({
            "query_text": ranking_result.get("query_text",""),
            "ranked_top3_docids": [c.get("DocId") for c in top3_raw],
            "stage1": ranking_result.get("stage1", {}),
            "ranked_top3_meta": [
                {
                    "DocId": c.get("DocId"),
                    "score_text": c.get("score_text"),
                    "score_text_norm": c.get("score_text_norm"),
                    "final_score": c.get("final_score"),
                } for c in top3_raw
            ],
            "judge_result": judge_result,
            "meta": {"model": MODEL, "temperature": temperature},
        })

        # å¯©æŸ»çµæœ
        st.markdown("### ğŸ† å¯©æŸ»çµæœï¼ˆLLMã«ã‚ˆã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®æ­£ã—ã•åˆ¤å®šï¼‰")
        # è¡¨ç¤ºå†…å®¹ï¼š1ä½ã®DocIdã‹ã‚‰ä¸»è¦æƒ…å ±ã‚’æŠœç²‹
        ranking = judge_result.get("ranking", [])
        if len(ranking) == 0:
            st.write("å¯©æŸ»çµæœãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        else:
            is_similar = judge_result.get("decision", {}).get("is_similar_enough")
            if is_similar is True:
                st.success("âœ… ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯æ­£ã—ã„")
            elif is_similar is False:
                st.error("âŒ ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯æ­£ã—ããªã„")
            else:
                st.info("â„¹ï¸ åˆ¤å®šã§ããš")
            
            st.markdown(f"**{judge_result.get('decision').get('summary')}**")
            top_rank = ranking[0]
            top_docid = top_rank.get("doc_id")
            top_candidate = next((c for c in search_top3 if c["DocId"] == top_docid), None)
            if top_candidate:
                st.markdown(f"#### â“è³ªå•æ–‡ï¼š{query}")
                st.markdown(f"**â˜†æœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹å€™è£œâ˜† DocId: {top_docid}ï¼{excerpt(top_candidate.get('SectionText'))}**")
                ranktbl = []
                ranktbl.append("ãƒ©ãƒ³ã‚­ãƒ³ã‚°|DocId | æ‚£è€…ID | é€€é™¢æ—¥ | ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹æŠœç²‹")
                ranktbl.append("--| -- | -- | -- | --")
                num=0
                for reco in search_top3:
                    num+=1
                    ranktbl.append(
                        f"{num}|{reco.get('DocId')}|{reco.get('PatientId')}|{reco.get('DischargeDate')}|{reco.get('SectionText')}"                        
                    )
                st.markdown("\n".join(ranktbl))
            else:
                st.write("æœ€ã‚‚é¡ä¼¼ã—ã¦ã„ã‚‹å€™è£œã®è©³ç´°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

        with st.expander("ğŸ” ãƒ©ãƒ³ã‚­ãƒ³ã‚°å¯©æŸ»çµæœï¼šãƒ‡ãƒãƒƒã‚°", expanded=False):
            st.write(judge_result)
